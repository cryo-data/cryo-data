
#+PROPERTY: header-args:bash+ :var githost="file:///home/kdm/tmp/cryo-data.dev"
#+PROPERTY: header-args:bash+ :var root="."
#+PROPERTY: header-args:bash+ :tangle cryo-data.sh
#+PROPERTY: header-args:bash+ :results verbatim :epilogue ":"
#+PROPERTY: header-args:bash+ :prologue exec 2>&1
#+PROPERTY: header-args:bash+ :prologue "source ~/.bash_profile; conda activate datalad"
#+PROPERTY: header-args:bash+ :prologue#  ls # conda activate datalad

* Table of contents                               :toc_2:noexport:
- [[#introduction][Introduction]]
- [[#use][Use]]
- [[#build][Build]]
  - [[#build-folder][=build= folder]]
- [[#archive][Archive]]

* Introduction

+ This file is the workbook for generating the cryo-data data meta-set

* Use

#+BEGIN_SRC bash :tangle no
trash ~/tmp/cryo-data.use
mkdir -p ~/tmp/cryo-data.use
cd ~/tmp/cryo-data.use
datalad clone ${githost}/cryo-data
cd cryo-data
datalad get -rn *
tree -d # list folders
find . | grep -v git # list files
#+END_SRC

* Build
** =build= folder

+ The =build= folder contains all sub-datasets (SD).
+ This is only a local folder on the dev machine.
+ Each SD is built as an isolated and stand-alone product.
+ Each SD is then pushed to its own repository under the [[https://github.com/cryo-data/][cryo-data]] Organization on GitHub
  + Note - the cryo-data Org will therefore become very messy.
  + We could create a cryo-data-dev Org?
  + Alternatively, we just point people to [[https://github.com/cryo-data/cryo-data][cryo-data/cryo-data]] - the top level datalad dataset
+ The cryo-data dataset (under the cryo-data Org) is then used to host all SD
  + The cryo-data dataset is created, with themed sub-folders
    + =author= contains all SDs that have a related =author_yyyy= publication.
      + Examples: mankoff_2020a, mankoff_2020b, lÃ¼thi_2002
    + =project= contains project names, and then all SDs related to those projects.
      + Examples: MEaSUREs/monthly_ice_velocity, PROMICE/mass_balance, GRISO/, MOSAIC/, etc.
    + =product= contains product names, and then all SDs related to those products.
      + Examples: BedMachine, MEaSUREs/monthly_ice_velocity, PROMICE/mass_balance, ArcticDEM, etc.
    + =org= contains organization names, and then all SDs related to those organizations.
      + Examples: NDSIC/0642, GEUS/mass_balance, NASA/ITS_LIVE, etc.
    + =misc= or =other= contains any datasets that do not fit into one or more of the above.
    + =db= contains all of the SDs from =build=, but linked to their remote location on GitHub, not the local =build= folder.
      + This is optional - we may not want to expose everything with our internal naming scheme.

#+BEGIN_SRC bash
mkdir -p ${root}/build
cd ${root}/build
#+END_SRC

#+RESULTS:

Also create the top-level =cryo-data= folder, and the =cryo-data/db= folder that will hold all of the SDs (that is, the =build= folder contents), but with the remote link, not from the local =build= folder.

*** top-level cryo-data folder on github

#+BEGIN_SRC bash
cd ${root}/build
trash cryo-data
datalad create -D "cryo-data" cryo-data
gh repo create --public -d 'cryo-data top-level datalad dataset' cryo-data/cryo-data
git remote add origin git@github.com:cryo-data/cryo-data.git
git push -u origin main
datalad push
#+END_SRC

*** Sub-datasets under cryo-data

#+BEGIN_SRC bash
cd ${root}/cryo-data

for dest in author project product repository misc; do
  datalad create -D "cryo-data by $dest" ${dest}
  cd ${dest}
  gh repo create --public -d 'cryo-data datalad dataset by ${dest}' cryo-data/${dest}
  git remote add origin git@github.com:cryo-data/${dest}.git
  git push -u origin main
  datalad push
  cd ..
done

# Add target "db" that contains everything?

datalad save -r
datalad push
#+END_SRC


*** Example
**** Build a dataset

#+BEGIN_SRC bash :async
cd ${root}/build
datalad create -D "data description" data
cd data

## Download files and add using one of...
# https://docs.datalad.org/en/stable/generated/man/datalad-download-url.html
# https://docs.datalad.org/en/stable/generated/man/datalad-addurls.html
# example: datalad download-url -m "commit msg" http://url/to/file
## or, create locally:
echo "Hello world" >> README.org
git add README.org
git commit -m "Add README.org"
datalad save
#+END_SRC

**** Push dataset to GitHub cryo-data Org account

#+BEGIN_SRC bash :async
gh repo create --public -d 'SD description' cryo-data/data
git remote add origin git@github.com:cryo-data/data
git push -u origin main
datalad push
#+END_SRC

**** Install dataset

#+BEGIN_SRC bash :async
### Install into the cryo-data db and author folder
cd ${root}/cryo-data/cryo-data
datalad clone git@github.com:cryo-data/data ./db/data
datalad clone git@github.com:cryo-data/data ./db/author_yyyy
#+END_SRC


*** NOTDONE PROMICE TMB

#+BEGIN_SRC bash :async
cd build
datalad create -D "PROMICE total mass balance" 10.22008-TMB
cd 10.22008-TMB

# fetch files
datalad download-url -m "mb_region.nc" "https://dataverse01.geus.dk/api/access/datafile/:persistentId?persistentId=doi:10.22008/FK2/OHI23Z/DAQCFT" -O "mb_region.nc"

datalad download-url -m "mb_sector.nc" "https://dataverse01.geus.dk/api/access/datafile/:persistentId?persistentId=doi:10.22008/FK2/OHI23Z/8PYG21" -O "mb_sector.nc"

datalad download-url -m "MB_SMB_D_BMB.csv" "https://dataverse01.geus.dk/api/access/datafile/:persistentId?persistentId=doi:10.22008/FK2/OHI23Z/GKPQD5" -O "MB_SMB_D_BMB.csv"

datalad download-url -m "MB_SMB_D_BMB_ANN.csv" "https://dataverse01.geus.dk/api/access/datafile/:persistentId?persistentId=doi:10.22008/FK2/OHI23Z/TIPMGB" -O "MB_SMB_D_BMB_ANN.csv"
#+END_SRC

#+RESULTS:

*** DONE PROMICE AWS
 
#+BEGIN_SRC bash :async
cd ${root}/build
datalad create -D "PROMICE AWS" 10.22008-AWS
cd 10.22008-AWS

datalad download-url -m "PROMICE AWS coordinates" https://promice.org/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/PROMICE_coordinates.pdf
datalad download-url -m "PROMICE AWS data file" https://promice.org/PromiceDataPortal/api/download/f24019f7-d586-4465-8181-d4965421e6eb/v03/monthly/CEN_month_v03.txt -O ./v03/monthly/CEN_month_v03.txt


###
### Push dataset to GitHub cryo-data/db repository, then install to db and parent, then push those changes
###
# push
# cd ~/projects/cryo-data/cryo-data/db/10.22008-AWS/
# gh repo create --public -d 'PROMICE AWS' cryo-data/10.22008-AWS
# git remote add origin git@github.com:cryo-data/10.22008-AWS
# git push -u origin main
# datalad push
#+END_SRC

#+BEGIN_SRC bash :async

# install and save
cd ~/projects/cryo-data/data/db
datalad install -d . https://github.com/cryo-data/subdataset
datalad save -m "Added subdataset"
datalad push

#+END_SRC

*** NSIDC
**** MEaSUREs
***** MEaSUREs 0645

+ https://n5eil01u.ecs.nsidc.org/MEASURES/NSIDC-0645.001/
+ DOI:10.5067/NV34YUIXLP9W

#+BEGIN_SRC bash
cd ~/projects/cryo-data/cryo-data/db
datalad create -D "MEaSUREs 0645" 10.5067-NV34YUIXLP9W
cd 10.5067-NV34YUIXLP9W

# fetch data
wget --load-cookies ~/.urs_cookies --save-cookies ~/.urs_cookies --keep-session-cookies --no-check-certificate --auth-no-challenge=on -r --reject "index.html*" -d -r -np -N --spider -e robots=off https://n5eil01u.ecs.nsidc.org/MEASURES/NSIDC-0645.001/ 2>&1 | grep " -> " | grep -Ev "\/\?C=" | sed "s/.* -> //" > urls_0.csv

echo "file,link" > urls_1.csv
cat urls_0.csv | grep "NSIDC-0645.001/.*/gimpdem*" | grep -v "UTF-8" | sort| uniq | while read line || [[ -n "$line" ]];
do
    printf "%s,%s\n" $(echo ${line} | cut -d"/" -f5-) ${line}
done | grep -v ",$" | grep -E 'file,link|\.tif$|\.xml$' >> urls_1.csv

datalad addurls --fast urls_1.csv '{link}' '{file}'
#+END_SRC


**** DONE BedMachine


+ https://n5eil01u.ecs.nsidc.org/MEASURES/NSIDC-0645.001/
+ DOI:10.5067/VLJ5YXKCNGXO

#+BEGIN_SRC bash
cd ${root}/build
datalad create -D "BedMachine v4" 10.5067-VLJ5YXKCNGXO
cd 10.5067-VLJ5YXKCNGXO

datalad download-url -m "BedMachine v4 XML" "https://n5eil01u.ecs.nsidc.org/ICEBRIDGE/IDBMG4.004/1993.01.01/BedMachineGreenland-2021-04-20.nc.xml"
# datalad download-url -m "BedMachine v4" "https://n5eil01u.ecs.nsidc.org/ICEBRIDGE/IDBMG4.004/1993.01.01/BedMachineGreenland-2021-04-20.nc"

cd ${root}/cryo-data/db
datalad clone ${root}/build/10.5067-VLJ5YXKCNGXO
datalad save -m "Add BedMachine"
cd ${root}/cryo-data/
datalad save -m "Add db/BedMachine"
#+END_SRC

*** author

#+BEGIN_SRC bash
cd ${root}/cryo-data
datalad create -D "cryo-data organized by author" author
cd author

datalad clone ${root}/cryo-data/db/10.5067-VLJ5YXKCNGXO ./morlighem_2017
datalad save -m "Morlighem 2017"
cd ..
datalad save -m "author/Morlighem 2017"



# datalad install -d . --source=../db/10.22008-TMB ./mankoff_2021
# datalad install -d . --source=../db/10.22008-discharge ./mankoff_2020
# datalad install -d . --source=../db/10.22008-AWS ./fausto_2021

# # datalad install -d . --source=../db/10.5067-VLJ5YXKCNGXO/ ./morlighem_2017
# datalad install -d . --source=../db/10.5067-NV34YUIXLP9W/ ./howat_2014
#+END_SRC

*** product

#+BEGIN_SRC bash
datalad create -D "cryo-data organized by product" product
cd product

# datalad install -d . --source=../db/10.5067-VLJ5YXKCNGXO/ ./BedMachine
#+END_SRC


*** project

#+BEGIN_SRC bash
datalad create -D "cryo-data organized by project" project
cd project

datalad create -D "PROMICE project" PROMICE
cd PROMICE
datalad install -d . --source=../../db/10.22008-TMB ./total_mass_balance
datalad install -d . --source=../../db/10.22008-discharge ./solid_ice_discharge
datalad install -d . --source=../../db/10.22008-AWS ./AWS

cd ..

datalad create -D "MEaSUREs project" MEaSUREs
cd MEaSUREs
datalad install -d . --source=../../db/10.5067-NV34YUIXLP9W/ ./NSIDC-0645
#+END_SRC


*** organization

#+BEGIN_SRC bash
datalad create -D "cryo-data organized by organization" org
cd org

datalad create -D "GEUS Org" GEUS
cd GEUS
datalad install -d . --source=../../db/10.22008-TMB ./total_mass_balance
datalad install -d . --source=../../db/10.22008-discharge ./solid_ice_discharge
datalad install -d . --source=../../db/10.22008-AWS ./AWS

cd ../

datalad create -D "NSIDC Org" NSIDC
cd NSIDC
datalad install -d . --source=../../db/10.5067-NV34YUIXLP9W/ ./NSIDC-0645
# datalad install -d . --source=../../db/10.5067-VLJ5YXKCNGXO/ ./BedMachine
#+END_SRC


*** NOTDONE Misc
#+BEGIN_SRC bash
cd cryo-data

datalad install -d . --source=../db
datalad install -d . --source=../project
datalad install -d . --source=../author
datalad install -d . --source=../org
datalad save


#+END_SRC
* Archive

Ingest 
+ https://github.com/cryo-data/test_foo
+ https://github.com/cryo-data/test_bar

#+BEGIN_SRC bash
datalad create -D "Test Foo" test_foo
(cd test_foo; datalad clone --dataset . https://github.com/cryo-data/test_foo)

datalad create -D "Test Bar" test_bar
(cd test_bar; datalad clone --dataset . https://github.com/cryo-data/test_bar)
#+END_SRC


